{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b71ebc-af1e-4ca5-81bb-619544d6e257",
   "metadata": {},
   "source": [
    "# 1 - Importing libraries and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c582e978-4bd5-4f86-a22a-c60ab7416341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Text processing libraries\n",
    "import emoji\n",
    "import re\n",
    "import contractions\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "## Feature Extraction Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classifier Model libraries\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Performance Matrix libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# other\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10595198-ccac-4fde-9f1c-43e180d12df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43410, 29)\n",
      "(5426, 29)\n",
      "(5427, 29)\n"
     ]
    }
   ],
   "source": [
    "# Importing train, validation and test datasets with preprocessed texts and labels\n",
    "train_GE = pd.read_csv(\"./train_clean.csv\")\n",
    "val_GE = pd.read_csv(\"./val_clean.csv\")\n",
    "test_GE = pd.read_csv(\"./test_clean.csv\")\n",
    "\n",
    "# Shape validation\n",
    "print(train_GE.shape)\n",
    "print(val_GE.shape)\n",
    "print(test_GE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "154aadc2-eda9-48bd-88f1-32c2b7638007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiration\n",
      "amusement\n",
      "anger\n",
      "annoyance\n",
      "approval\n",
      "caring\n",
      "confusion\n",
      "curiosity\n",
      "desire\n",
      "disappointment\n",
      "disapproval\n",
      "disgust\n",
      "embarrassment\n",
      "excitement\n",
      "fear\n",
      "gratitude\n",
      "grief\n",
      "joy\n",
      "love\n",
      "nervousness\n",
      "optimism\n",
      "pride\n",
      "realization\n",
      "relief\n",
      "remorse\n",
      "sadness\n",
      "surprise\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "# Loading emotion labels\n",
    "with open(\"./emotions.txt\", \"r\") as file :\n",
    "    emotions = file.read().split(\"\\n\")\n",
    "\n",
    "for emo in emotions :\n",
    "    print(emo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e708ed7-d182-4962-8ace-ce883d633970",
   "metadata": {},
   "source": [
    "# 2 - Preprocessing and transformations\n",
    "\n",
    "## 2.1 - Additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0210d202-e9d1-4a10-acfc-cedf66e06cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Download model \n",
    "!python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3c9e782-2b21-4e38-aa94-cd2d5e6d0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import English using en_core_web_sm.load()\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7ea5022-32a8-47b9-9b55-ebaa2a82b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tokenized documents\n",
    "tokenized_train_GE = list(nlp.pipe(train_GE[\"Clean_text\"]))\n",
    "tokenized_test_GE = list(nlp.pipe(test_GE[\"Clean_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f44ab693-4e5f-4095-82f6-e08caa1a2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "tokenized_train_GE = [\n",
    "    [token.lemma_ for token in doc if token.lemma_ not in STOP_WORDS]\n",
    "    for doc in tokenized_train_GE\n",
    "]\n",
    "\n",
    "tokenized_test_GE = [\n",
    "    [token.lemma_ for token in doc if token.lemma_ not in STOP_WORDS]\n",
    "    for doc in tokenized_test_GE\n",
    "]\n",
    "\n",
    "train_GE[\"Clean_token\"] = [\" \".join(tokens) for tokens in tokenized_train_GE]\n",
    "test_GE[\"Clean_token\"] = [\" \".join(tokens) for tokens in tokenized_test_GE]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b9c443-c78d-4c2f-aeea-13c09b16b7e4",
   "metadata": {},
   "source": [
    "## 2.2 - Create TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "252a5123-7d87-478e-9fcd-101ac169f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43410, 1000)\n",
      "(5427, 1000)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF vector with 1000 words vocabulary \n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
    "\n",
    "# Fitting the vectorizer and transforming train and test data\n",
    "tfidf_train_GE = vectorizer.fit_transform(train_GE['Clean_token'])\n",
    "tfidf_test_GE = vectorizer.transform(test_GE['Clean_token'])\n",
    "\n",
    "# Transforming from generators to arrays\n",
    "tfidf_train_GE = tfidf_train_GE.toarray()\n",
    "tfidf_test_GE = tfidf_test_GE.toarray()\n",
    "\n",
    "# Validating the shape of train and test data\n",
    "print(tfidf_train_GE.shape)\n",
    "print(tfidf_test_GE.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8ee48-e5d0-42c3-8e2d-aeea1d51fb54",
   "metadata": {},
   "source": [
    "## 2.3 - Train and test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40127b36-2389-4f86-b517-d0423cacd9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is :  (43410, 1000)\n",
      "The shape of y_train is :  (43410, 28)\n",
      "\n",
      "The shape of X_test is :  (5427, 1000)\n",
      "The shape of y_test is :  (5427, 28)\n"
     ]
    }
   ],
   "source": [
    "# Defining train and test variables\n",
    "x_train =  tfidf_train_GE\n",
    "y_train = train_GE.loc[:,emotions].values\n",
    "\n",
    "x_test =  tfidf_test_GE\n",
    "y_test = test_GE.loc[:,emotions].values\n",
    "\n",
    "# Shape validation\n",
    "print(\"The shape of X_train is : \", x_train.shape)\n",
    "print(\"The shape of y_train is : \", y_train.shape)\n",
    "print()\n",
    "print(\"The shape of X_test is : \", x_test.shape)\n",
    "print(\"The shape of y_test is : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f8237-9732-44d3-a6d9-5cd811a6d2ed",
   "metadata": {},
   "source": [
    "# 3 - Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "590d579c-c7c1-42c9-bdad-58b540b17a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7233e991-47fc-4535-8935-c3ffd7827fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": OneVsRestClassifier(\n",
    "        LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            class_weight=\"balanced\"\n",
    "        )\n",
    "    ),\n",
    "    \"Linear SVM\": OneVsRestClassifier(\n",
    "        LinearSVC()\n",
    "    ),\n",
    "    \"SGD Classifier\": OneVsRestClassifier(\n",
    "        SGDClassifier(\n",
    "            loss=\"log_loss\",\n",
    "            max_iter=1000\n",
    "        )\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1be88c7e-f603-4bcc-91f4-44bfd6031574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Training Linear SVM...\n",
      "\n",
      "Training SGD Classifier...\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average=\"micro\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average=\"micro\", zero_division=0),\n",
    "        \"F1-score\": f1_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cc6cf86-95af-406f-bf6e-fcc474fc3ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression =====\n",
      "Accuracy  : 0.0374\n",
      "Precision : 0.1931\n",
      "Recall    : 0.7306\n",
      "F1-score  : 0.3054\n",
      "\n",
      "===== Linear SVM =====\n",
      "Accuracy  : 0.3228\n",
      "Precision : 0.6811\n",
      "Recall    : 0.3395\n",
      "F1-score  : 0.4532\n",
      "\n",
      "===== SGD Classifier =====\n",
      "Accuracy  : 0.2432\n",
      "Precision : 0.6963\n",
      "Recall    : 0.2485\n",
      "F1-score  : 0.3663\n"
     ]
    }
   ],
   "source": [
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric:<10}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9b53e79-ba43-4bbc-bb15-9d75dc344c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving initial text preprocessings\n",
    "def preprocess_corpus(x):\n",
    "    \n",
    "    # Adding a space between words and punctation\n",
    "    x = re.sub( r'([a-zA-Z\\[\\]])([,;.!?])', r'\\1 \\2', x)\n",
    "    x = re.sub( r'([,;.!?])([a-zA-Z\\[\\]])', r'\\1 \\2', x)\n",
    "\n",
    "    # Demojize\n",
    "    x = emoji.demojize(x)\n",
    "\n",
    "    # Expand contraction\n",
    "    x = contractions.fix(x)\n",
    "\n",
    "    # Lower\n",
    "    x = x.lower()\n",
    "\n",
    "    #correct some acronyms/typos/abbreviations  \n",
    "    x = re.sub(r\"lmao\", \"laughing my ass off\", x)  \n",
    "    x = re.sub(r\"amirite\", \"am i right\", x)\n",
    "    x = re.sub(r\"\\b(tho)\\b\", \"though\", x)\n",
    "    x = re.sub(r\"\\b(ikr)\\b\", \"i know right\", x)\n",
    "    x = re.sub(r\"\\b(ya|u)\\b\", \"you\", x)\n",
    "    x = re.sub(r\"\\b(eu)\\b\", \"europe\", x)\n",
    "    x = re.sub(r\"\\b(da)\\b\", \"the\", x)\n",
    "    x = re.sub(r\"\\b(dat)\\b\", \"that\", x)\n",
    "    x = re.sub(r\"\\b(dats)\\b\", \"that is\", x)\n",
    "    x = re.sub(r\"\\b(cuz)\\b\", \"because\", x)\n",
    "    x = re.sub(r\"\\b(fkn)\\b\", \"fucking\", x)\n",
    "    x = re.sub(r\"\\b(tbh)\\b\", \"to be honest\", x)\n",
    "    x = re.sub(r\"\\b(tbf)\\b\", \"to be fair\", x)\n",
    "    x = re.sub(r\"faux pas\", \"mistake\", x)\n",
    "    x = re.sub(r\"\\b(btw)\\b\", \"by the way\", x)\n",
    "    x = re.sub(r\"\\b(bs)\\b\", \"bullshit\", x)\n",
    "    x = re.sub(r\"\\b(kinda)\\b\", \"kind of\", x)\n",
    "    x = re.sub(r\"\\b(bruh)\\b\", \"bro\", x)\n",
    "    x = re.sub(r\"\\b(w/e)\\b\", \"whatever\", x)\n",
    "    x = re.sub(r\"\\b(w/)\\b\", \"with\", x)\n",
    "    x = re.sub(r\"\\b(w/o)\\b\", \"without\", x)\n",
    "    x = re.sub(r\"\\b(doj)\\b\", \"department of justice\", x)\n",
    "\n",
    "    # replace some words with multiple occurences of a letter, example \"coooool\" turns into --> cool\n",
    "    x = re.sub(r\"\\b(j+e{2,}z+e*)\\b\", \"jeez\", x)\n",
    "    x = re.sub(r\"\\b(co+l+)\\b\", \"cool\", x)\n",
    "    x = re.sub(r\"\\b(g+o+a+l+)\\b\", \"goal\", x)\n",
    "    x = re.sub(r\"\\b(s+h+i+t+)\\b\", \"shit\", x)\n",
    "    x = re.sub(r\"\\b(o+m+g+)\\b\", \"omg\", x)\n",
    "    x = re.sub(r\"\\b(w+t+f+)\\b\", \"wtf\", x)\n",
    "    x = re.sub(r\"\\b(w+h+a+t+)\\b\", \"what\", x)\n",
    "    x = re.sub(r\"\\b(y+e+y+|y+a+y+|y+e+a+h+)\\b\", \"yeah\", x)\n",
    "    x = re.sub(r\"\\b(w+o+w+)\\b\", \"wow\", x)\n",
    "    x = re.sub(r\"\\b(w+h+y+)\\b\", \"why\", x)\n",
    "    x = re.sub(r\"\\b(s+o+)\\b\", \"so\", x)\n",
    "    x = re.sub(r\"\\b(f)\\b\", \"fuck\", x)\n",
    "    x = re.sub(r\"\\b(w+h+o+p+s+)\\b\", \"whoops\", x)\n",
    "    x = re.sub(r\"\\b(ofc)\\b\", \"of course\", x)\n",
    "    x = re.sub(r\"\\b(the us)\\b\", \"usa\", x)\n",
    "    x = re.sub(r\"\\b(gf)\\b\", \"girlfriend\", x)\n",
    "    x = re.sub(r\"\\b(hr)\\b\", \"human ressources\", x)\n",
    "    x = re.sub(r\"\\b(mh)\\b\", \"mental health\", x)\n",
    "    x = re.sub(r\"\\b(idk)\\b\", \"i do not know\", x)\n",
    "    x = re.sub(r\"\\b(gotcha)\\b\", \"i got you\", x)\n",
    "    x = re.sub(r\"\\b(y+e+p+)\\b\", \"yes\", x)\n",
    "    x = re.sub(r\"\\b(a*ha+h[ha]*|a*ha +h[ha]*)\\b\", \"haha\", x)\n",
    "    x = re.sub(r\"\\b(o?l+o+l+[ol]*)\\b\", \"lol\", x)\n",
    "    x = re.sub(r\"\\b(o*ho+h[ho]*|o*ho +h[ho]*)\\b\", \"ohoh\", x)\n",
    "    x = re.sub(r\"\\b(o+h+)\\b\", \"oh\", x)\n",
    "    x = re.sub(r\"\\b(a+h+)\\b\", \"ah\", x)\n",
    "    x = re.sub(r\"\\b(u+h+)\\b\", \"uh\", x)\n",
    "\n",
    "    # Handling emojis\n",
    "    x = re.sub(r\"<3\", \" love \", x)\n",
    "    x = re.sub(r\"xd\", \" smiling_face_with_open_mouth_and_tightly_closed_eyes \", x)\n",
    "    x = re.sub(r\":\\)\", \" smiling_face \", x)\n",
    "    x = re.sub(r\"^_^\", \" smiling_face \", x)\n",
    "    x = re.sub(r\"\\*_\\*\", \" star_struck \", x)\n",
    "    x = re.sub(r\":\\(\", \" frowning_face \", x)\n",
    "    x = re.sub(r\":\\^\\(\", \" frowning_face \", x)\n",
    "    x = re.sub(r\";\\(\", \" frowning_face \", x)\n",
    "    x = re.sub(r\":\\/\",  \" confused_face\", x)\n",
    "    x = re.sub(r\";\\)\",  \" wink\", x)\n",
    "    x = re.sub(r\">__<\",  \" unamused \", x)\n",
    "    x = re.sub(r\"\\b([xo]+x*)\\b\", \" xoxo \", x)\n",
    "    x = re.sub(r\"\\b(n+a+h+)\\b\", \"no\", x)\n",
    "    \n",
    "    # Handling special cases of text\n",
    "    x = re.sub(r\"h a m b e r d e r s\", \"hamberders\", x)\n",
    "    x = re.sub(r\"b e n\", \"ben\", x)\n",
    "    x = re.sub(r\"s a t i r e\", \"satire\", x)\n",
    "    x = re.sub(r\"y i k e s\", \"yikes\", x)\n",
    "    x = re.sub(r\"s p o i l e r\", \"spoiler\", x)\n",
    "    x = re.sub(r\"thankyou\", \"thank you\", x)\n",
    "    x = re.sub(r\"a^r^o^o^o^o^o^o^o^n^d\", \"around\", x)\n",
    "\n",
    "    # Remove special characters and numbers replace by space + remove double space\n",
    "    x = re.sub(r\"\\b([.]{3,})\",\" dots \", x)\n",
    "    x = re.sub(r\"[^A-Za-z!?_]+\",\" \", x)\n",
    "    x = re.sub(r\"\\b([s])\\b *\",\"\", x)\n",
    "    x = re.sub(r\" +\",\" \", x)\n",
    "    x = x.strip()\n",
    "\n",
    "    return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "396ec66f-96c3-44d0-81ca-6ce449341a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_samples(text_samples, model):\n",
    "    # Ensure input is a list\n",
    "    if isinstance(text_samples, str):\n",
    "        text_samples = [text_samples]\n",
    "\n",
    "    # Text preprocessing\n",
    "    text_samples = pd.Series(text_samples)\n",
    "    text_samples_clean = text_samples.apply(preprocess_corpus)\n",
    "\n",
    "    # TF-IDF transformation\n",
    "    tfidf_text_samples = vectorizer.transform(text_samples_clean)\n",
    "\n",
    "    # Predictions\n",
    "    samples_pred_labels = model.predict(tfidf_text_samples)\n",
    "\n",
    "    samples_pred_labels_df = pd.DataFrame(samples_pred_labels)\n",
    "\n",
    "    samples_pred_emotions = samples_pred_labels_df.apply(\n",
    "        lambda x: [emotions[i] for i in range(len(x)) if x[i] == 1],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Final result\n",
    "    return pd.DataFrame({\n",
    "        \"Text\": text_samples,\n",
    "        \"Emotions\": samples_pred_emotions\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fb97951-d3fd-435e-9f4a-1e8cb533d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Text                                           Emotions\n",
      "0     no one cares my guy                               [curiosity, neutral]\n",
      "1     I am so happy today                           [excitement, joy, pride]\n",
      "2  I feel empty and tired  [annoyance, caring, disappointment, nervousnes...\n",
      "\n",
      "                     Text   Emotions\n",
      "0     no one cares my guy  [neutral]\n",
      "1     I am so happy today      [joy]\n",
      "2  I feel empty and tired         []\n",
      "\n",
      "                     Text   Emotions\n",
      "0     no one cares my guy  [neutral]\n",
      "1     I am so happy today      [joy]\n",
      "2  I feel empty and tired         []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items() :\n",
    "    samples = [\n",
    "        \"no one cares my guy\",\n",
    "        \"I am so happy today\",\n",
    "        \"I feel empty and tired\"\n",
    "    ]\n",
    "    \n",
    "    result = predict_samples(samples, model)\n",
    "    \n",
    "    print(result)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
